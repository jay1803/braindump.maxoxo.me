+++
title = "It takes a Flywheel to Fly: Kickstarting and Keeping the A/B testing Momentum"
author = ["Max Zhang"]
draft = false
+++

## It takes a Flywheel to Fly: Kickstarting and Keeping the A/B testing Momentum {#it-takes-a-flywheel-to-fly-kickstarting-and-keeping-the-a-b-testing-momentum}


### What is a Flywheel? {#what-is-a-flywheel}

The concept of a flywheel was presented in the book “Good to Great”,
illustrating that good-to-great transformations never happen at once but, you
guessed it, in turns. Every flywheel consists of a few carefully derived steps
that logically follow each other in a loop.

{{< figure src="/ox-hugo/2022-03-15_22-41-02_ABTestingFlywheel.png" >}}

We introduce the steps next, starting with the goal-step of being able to
support more decisions through A/B testing.

1.  Running more A/B tests to support more decisions. At the top of the flywheel
    is the goal – using A/B tests to support decision making. With every turn of
    the flywheel, we aim to run more A/B tests to support more decisions.
2.  Measure value to decision making. While not every A/B test has substantial
    impact on decisions, some A/B tests do, and the impact and value added by A/B
    tests need to be measured and captured. The more A/B tests we run with each
    turn of the flywheel, the more aggregate value and impact the A/B testing
    program will provide.
3.  Increasing interest in A/B testing. When A/B testing is ran by one team and
    those results are shared broadly, this can lead to interest in A/B testing by
    new teams and new A/B testing scenarios. To support this spread of interest,
    the value of A/B tests needs to be broadly communicated. Additionally,
    educational and support efforts are needed to support new teams interested in
    using A/B testing to ensure their initial experience with A/B testing is a
    success.
4.  Investing in A/B testing infrastructure and data quality. The more interest
    and willingness there is to try A/B testing within an organization, the more
    resources can be justifiably allocated to make an A/B testing program
    successful. These resources should be directed towards two key areas:
    improving A/B testing capabilities for managing and analyzing A/B tests, and
    increasing data quality. The goal of these investments is to make A/B tests
    are more trustworthy and easier to execute.
5.  Lowering human cost of A/B testing. Improvements in A/B testing
    infrastructure and data quality create conditions for streamlining the A/B
    testing process and lowering its human cost i.e., the amount of investment
    required to start doing A/B testing in a new area. Lowering the cost of A/B
    testing is a critical step in the flywheel that is often missed. If running
    A/B tests remains costly, A/B testing will remain limited to highly
    interested early adopters with a lot of resources. This step increases the
    return on investment (ROI) of A/B testing by reducing the “I” and making it
    worthwhile for more teams who may be less convinced about the “R” or are more
    resource constrained, to try running A/B tests.


### Introducing the A/B testing Flywheel {#introducing-the-a-b-testing-flywheel}


### The first turn {#the-first-turn}


### Making the A/B testing Flywheel Spin {#making-the-a-b-testing-flywheel-spin}